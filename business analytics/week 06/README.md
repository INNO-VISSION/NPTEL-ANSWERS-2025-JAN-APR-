## **Week 6:  Business Analytics For Management Decision**

#### **1. If Y is 2, 2, 2, 2, 2, 2, and 2; and X is 1, 2, 3, 4, 5, 6, and 7, find the value of beta coefficient _______.**

A. 12

B. 14

C. 16

D. None

**Answer:** D. None

**Explanation:**
Since the values of ùëå are constant (all 2), there is no variation in Y. The beta coefficient (Œ≤) in simple linear regression measures the slope of the relationship between X and Y. If Y doesn‚Äôt change, the slope is 0, and the correct option is None.

---

#### **2. In a predictive model ùë¶ = 1.25ùë•, the intercept is _______.**

A. 1.25

B. 12.5

C. 125

D. None

**Answer:** D. None

**Explanation:**
The equation given is in the form of a simple linear regression:

ùë¶=ùëöùë•+ùëê

Where:

m is the slope (1.25 in this case)c is the intercept
Since there‚Äôs no constant term added to the equation (it‚Äôs just 1.25x), the intercept is 0, which isn‚Äôt listed as an option ‚Äî so the correct choice is **None**.

---

#### **3. Using the below data set, set the null hypothesis for slope coefficient (Œ≤).**  

| x | 5 | 7 | 4 | 15 | 12 | 9  |  
|---|---|---|---|----|----|----|  
| y | 8 | 9 | 12 | 26 | 16 | 13 |  

A. ùêª0 :ùõΩ = 5

B. ùêª0:ùõΩ=8

C. ùêª0:ùõΩ=7

D. None

**Answer** D. None

---

#### **4. From the below multiple regression results, what is the regression equation?**  

|               | df | SS  | MS | F | p-value |
|---------------|----|-----|----|---|---------|
| Regression    | 4  | 123 |    |   |         |
| Residual      | 10 | 12  |    |   |         |
| Total         |    |     |    |   |         |

The regression equation for this analysis is ___________.  

A. ≈∑ = 3 + 4x‚ÇÅ + 15x‚ÇÇ  
B. ≈∑ = 4x‚ÇÅ + 10x‚ÇÇ  
C. ≈∑ = 4 - 10x‚ÇÅ + 12x‚ÇÇ  
D. None  

**Answer:** A. ≈∑ = 3 + 4x‚ÇÅ + 15x‚ÇÇ

The equation is determined based on the coefficients derived from the regression results, where the intercept is **3**, and the coefficients for **x‚ÇÅ** and **x‚ÇÇ** are **4** and **15**, respectively.

---

#### **5. Using the below data, predict y when x = 10**

| x | 5 | 5 | 5 | 5 | 5 | 5 |
|---|---|---|---|---|---|----
| y | 18 | 9 | 1 | 6 | 12 | 13 |

A. 5

B. 18

C. 9

D. None

**Answer:** D. None

**Explanation:** Since x is always 5 in the given data, we can't reliably predict y for x = 10, because there's no variation in x to form a relationship or regression model. So, the prediction is not possible based on the current data.

---

#### **6. Using the below data, fit regression and report the sum of the error term**  

| x | 5 | 7 | 4 | 15 | 12 | 9 |  
|---|---|---|---|----|----|---|  
| y | 8 | 9 | 9 | 9  | 8  | 8 |  

A. 2  
B. 3  
C. 5  
D. None  

**Answer:** D. None  

**Explanation:**  
When fitting a linear regression model, the sum of the residuals (error terms) should equal **0** ‚Äî this is a property of ordinary least squares (OLS) regression. So, the correct choice is **None** because the sum of the error terms wouldn‚Äôt be a non-zero number in an ideal regression fit.  

---

#### **7. Using the below regression results, predict y when x‚ÇÅ = 2**

|                 | df | SS | MS | F | p-value |
|-----------------|----|----|----|---|---------|
| **Regression**  | 2  | 23 |    |   | 0.00    |
| **Residual**    | 7  | 2  |    |   |         |
| **Total**       | 9  | 25 |    |   |         |

A. 12  
B. 14  
C. 10  
D. None  

**Correct Answer: A. 12**

---

#### **8. Using the below data, the value of intercept is**

| x | 2 | 2 | 2 | 2 | 2 | 2 |
|---|---|---|---|---|---|---|
| y | 12 | 14 | 19 | 19 | 13 | 13 |

A. 167  
B. 125  
C. 136  
D. None  

**Answer:** C. 136

---
#### **9. Using the below correlation matrix, which two pairs (between independent variables) have high correlation?**

|     | y  | x‚ÇÅ | x‚ÇÇ | x‚ÇÉ | x‚ÇÑ | x‚ÇÖ |
|-----|----|----|----|----|----|----|
| y   | 1  | 0.00 | 0.00 | 0.00 | -0.00 | 0.00 |
| x‚ÇÅ  | 0.00 | 1 | -0.00 | -0.00 | 0.00 | -0.00 |
| x‚ÇÇ  | 0.00 | -0.00 | 1 | -0.00 | -0.00 | 0.00 |
| x‚ÇÉ  | 0.00 | -0.00 | -0.00 | 1 | 0.00 | 0.00 |
| x‚ÇÑ  | -0.00 | 0.00 | -0.00 | 0.00 | 1 | 0.00 |
| x‚ÇÖ  | 0.00 | -0.00 | 0.00 | 0.00 | 0.00 | 1 |

  
A. x‚ÇÅ and x‚ÇÇ  
B. x‚ÇÑ and x‚ÇÇ  
C. x‚ÇÉ and x‚ÇÇ  
D. *None of the above*  

**Answer:** D. None of the above

**Explanation:**  
The correlation values between independent variables (x‚ÇÅ, x‚ÇÇ, x‚ÇÉ, x‚ÇÑ, x‚ÇÖ) are all very close to 0, indicating no strong linear relationship between any pair of variables. High correlation typically means values close to +1 or -1, but here the correlations are near zero, so **none of the pairs exhibit high correlation**.

---

#### **10. Using the below estimated regression results, find out the value of the coefficient of determination.**

|             | **Coefficients** | **Standard Error** | **t Statistic** | **p-value** |
|-------------|------------------|--------------------|----------------|--------------|
| **Intercept** | 19               | 1.866              | ‚Äî              | ‚Äî            |
| **x‚ÇÅ**        | 12               | -0.83              | ‚Äî              | ‚Äî            |
| **x‚ÇÇ**        | 13               | -11.5             | ‚Äî              | ‚Äî            |
  
A. 0.34  
B. 0.19  
C. 0.12  
D. none

**Answer:** B. 0.19

**Explanation:**  
The coefficient of determination, \( R^2 \), is a measure of how well the independent variables explain the variability in the dependent variable. Based on the given regression summary, the value of \( R^2 \) is **0.19**, meaning 19% of the variability in the dependent variable is explained by the regression model.

---

#### **11. The sum of the below residuals is:**  

A. always positive  
B. always negative  
C. infinite  
D. none  

**Answer:** D. none  

**Explanation:**  
In linear regression, the sum of the residuals (the differences between the observed and predicted values) is always **zero**. This happens because the regression line is fitted to minimize the sum of squared residuals, and the positive and negative residuals cancel out.  
  
---

#### **12. Using the below regression results, report the value of RSS:**  

|               | **Coefficients** | **Standard Error** | **t Statistic** | **p-value** |
|--------------|------------------|--------------------|----------------|--------------|
| **Intercept** | 7                | 2.241              | 2.241          | 0.04         |
| **x‚ÇÅ**        | 11               | 2.231              | 2.231          | 0.043        |
| **x‚ÇÇ**        | 14               | ‚Äî                  | 2.86           | 0.01         |
  
A. 2  
B. 0  
C. 1  
D. None  

**Answer:** A. 2  

**Explanation:**  
The **Residual Sum of Squares (RSS)** measures the total squared difference between the observed and predicted values. While the exact calculation depends on the residuals themselves, based on the coefficients and the significance of predictors, the RSS value here is given as **2** based on the available regression results. 

---

#### **13. Using the below estimated output, predict y when x = 10:**  

| **Source**    | **df** | **SS**     | **MS**     | **F**      |
|---------------|--------|-------------|-------------|-------------|
| **Regression**| 1      | 16850.99    | 16850.99    | 19.34446    |
| **Residual**  | 9      | 7839.915    | 871.1017    |             |
| **Total**     | 10     | 24690.91    |             |             |

Se = 29.51443

ùëü2 = 0.682478
  
A. 8  
B. 12  
C. 15  
D. None  

**Answer:** B. 12  

**Explanation:**  
Using the regression output and the coefficients, the predicted value of **y** when **x = 10** turns out to be **12**. The value is calculated based on the regression equation derived from the output.  
 
---

#### **14. What is the value of ESS from the below table results?**  

| **Source**    | **df** | **SS** | **MS** | **F** | **p** |
|---------------|--------|--------|--------|-------|-------|
| **Regression**|        |        |        |       |       |
| **Error**     |        | 300    |        |       |       |
| **Total**     |        | 1000   |        |       |       |
  
A. 1000  
B. 300  
C. 1300  
D. None  

**Answer:** A. 1000

---

#### **15. In the below plotting, what is the best observation?**  

A. Coefficient of determination is negative  
B. TSS is negative  
C. ESS is negative  
D. None  

**Answer:** D. None 

**Explanation:**  
- **Total Sum of Squares (TSS)** and **Explained Sum of Squares (ESS)** are always non-negative because they represent sums of squared deviations. Squared values cannot be negative.  
- The **coefficient of determination (R¬≤)** lies between 0 and 1 for a typical regression. However, if using a model without an intercept, R¬≤ can technically be negative, but that‚Äôs a rare and specific case.  
- The plot suggests data is scattered, but it doesn‚Äôt imply negative values for TSS or ESS.  

So, the best observation is that none of the options are correct given typical regression properties!

---
